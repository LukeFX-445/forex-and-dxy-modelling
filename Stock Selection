# --- Enhanced S&P 500 Stock Selection with Advanced Forecasting & Sector Analysis ---
# Features: ML models, sector rotation, earnings impact, options-implied vol, factor models

import warnings
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)

!pip install yfinance arch pandas numpy scipy scikit-learn statsmodels fredapi beautifulsoup4 requests ta-lib-binary --quiet

import yfinance as yf
import pandas as pd
import numpy as np
from io import StringIO
from datetime import datetime, timedelta
import json
import sys
import time
import requests
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LassoCV
from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression
from bs4 import BeautifulSoup
import math

# ============================================================================
# SECTION 1: S&P 500 CONSTITUENTS & DATA COLLECTION
# ============================================================================

print("=" * 80)
print("ENHANCED S&P 500 STOCK FORECASTING SYSTEM - INITIALIZATION")
print("=" * 80)

def get_sp500_tickers():
    """Fetch current S&P 500 constituents from Wikipedia"""
    try:
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        tables = pd.read_html(url)
        df = tables[0]
        
        tickers = df['Symbol'].tolist()
        sectors = dict(zip(df['Symbol'], df['GICS Sector']))
        industries = dict(zip(df['Symbol'], df['GICS Sub-Industry']))
        
        # Clean ticker symbols (handle special cases)
        tickers = [t.replace('.', '-') for t in tickers]
        
        return tickers, sectors, industries
    except Exception as e:
        print(f"Warning: Failed to fetch S&P 500 list: {e}")
        # Fallback to major components
        return ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'BRK-B', 
                'UNH', 'JNJ', 'JPM', 'V', 'PG', 'MA', 'HD', 'CVX', 'MRK', 'ABBV',
                'PEP', 'KO', 'COST', 'AVGO', 'WMT', 'DIS', 'CSCO', 'ACN', 'LLY',
                'TMO', 'VZ', 'ADBE', 'NFLX', 'NKE', 'CMCSA', 'DHR', 'PM', 'TXN',
                'UPS', 'NEE', 'RTX', 'ORCL', 'INTC', 'CRM', 'AMD', 'QCOM', 'HON',
                'IBM', 'BA', 'GE', 'CAT', 'MMM'], {}, {}

print("\n[1/15] Fetching S&P 500 constituents...")
sp500_tickers, sector_map, industry_map = get_sp500_tickers()
print(f"‚úì Found {len(sp500_tickers)} S&P 500 stocks")

# For demonstration, we'll analyze top 100 by market cap (full 500 takes longer)
# In production, analyze all 500 or use parallel processing
print("\n[2/15] Selecting stocks for analysis...")

# Get market caps for top stocks
market_caps = {}
for ticker in sp500_tickers[:150]:  # Sample first 150
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        mc = info.get('marketCap', 0)
        if mc > 0:
            market_caps[ticker] = mc
    except:
        continue

# Select top 100 by market cap
top_stocks = sorted(market_caps.keys(), key=lambda x: market_caps[x], reverse=True)[:100]
print(f"‚úì Analyzing top {len(top_stocks)} stocks by market cap")

# ============================================================================
# SECTION 2: COMPREHENSIVE DATA COLLECTION
# ============================================================================

print("\n[3/15] Downloading price data and fundamentals...")

end_date = datetime.utcnow()
start_date = end_date - timedelta(days=3*365)

# Download price data
price_data = {}
volume_data = {}
fundamental_data = {}

for i, ticker in enumerate(top_stocks):
    try:
        if (i + 1) % 20 == 0:
            print(f"  Progress: {i+1}/{len(top_stocks)} stocks...")
        
        stock = yf.Ticker(ticker)
        
        # Historical prices
        hist = stock.history(start=start_date, end=end_date, auto_adjust=False)
        
        if hist.empty or len(hist) < 100:
            continue
        
        price_data[ticker] = hist['Close']
        volume_data[ticker] = hist['Volume']
        
        # Fundamental data
        info = stock.info
        fundamental_data[ticker] = {
            'sector': sector_map.get(ticker, info.get('sector', 'Unknown')),
            'industry': industry_map.get(ticker, info.get('industry', 'Unknown')),
            'market_cap': info.get('marketCap', 0),
            'pe_ratio': info.get('trailingPE', np.nan),
            'forward_pe': info.get('forwardPE', np.nan),
            'peg_ratio': info.get('pegRatio', np.nan),
            'price_to_book': info.get('priceToBook', np.nan),
            'dividend_yield': info.get('dividendYield', 0) * 100 if info.get('dividendYield') else 0,
            'profit_margin': info.get('profitMargins', 0) * 100 if info.get('profitMargins') else 0,
            'roe': info.get('returnOnEquity', 0) * 100 if info.get('returnOnEquity') else 0,
            'revenue_growth': info.get('revenueGrowth', 0) * 100 if info.get('revenueGrowth') else 0,
            'earnings_growth': info.get('earningsGrowth', 0) * 100 if info.get('earningsGrowth') else 0,
            'debt_to_equity': info.get('debtToEquity', np.nan),
            'current_ratio': info.get('currentRatio', np.nan),
            'beta': info.get('beta', 1.0),
            'short_ratio': info.get('shortRatio', np.nan),
            '52w_high': info.get('fiftyTwoWeekHigh', np.nan),
            '52w_low': info.get('fiftyTwoWeekLow', np.nan)
        }
        
        time.sleep(0.1)  # Rate limiting
        
    except Exception as e:
        print(f"  Warning: Failed to fetch {ticker}: {e}")
        continue

# Create price DataFrame
prices_df = pd.DataFrame(price_data)
prices_df = prices_df.dropna(how='all', axis=1)
prices_df = prices_df.ffill(limit=5).dropna(how='all')

volumes_df = pd.DataFrame(volume_data)
volumes_df = volumes_df.reindex(prices_df.index).ffill(limit=5)

stocks = list(prices_df.columns)
print(f"‚úì Collected data for {len(stocks)} stocks")

# Save fundamental data
fundamentals_df = pd.DataFrame(fundamental_data).T
fundamentals_df.to_csv('sp500_fundamentals.csv')

# ============================================================================
# SECTION 3: RETURNS & RISK METRICS
# ============================================================================

print("\n[4/15] Computing returns and risk metrics...")

# Log returns
returns = np.log(prices_df / prices_df.shift(1)).dropna()

# Simple returns for some calculations
simple_returns = prices_df.pct_change().dropna()

# Market benchmark (S&P 500 index)
spy = yf.download('SPY', start=start_date, end=end_date, progress=False)
spy_returns = np.log(spy['Close'] / spy['Close'].shift(1)).dropna()
spy_returns = spy_returns.reindex(returns.index).ffill()

# Calculate basic statistics
stats_dict = {}
for stock in stocks:
    ret = returns[stock].dropna()
    
    stats_dict[stock] = {
        'mean_daily_return': float(ret.mean()),
        'std_daily': float(ret.std()),
        'ann_return': float(ret.mean() * 252 * 100),
        'ann_volatility': float(ret.std() * np.sqrt(252) * 100),
        'sharpe_ratio': float(ret.mean() / ret.std() * np.sqrt(252)) if ret.std() > 0 else 0,
        'skewness': float(stats.skew(ret)),
        'kurtosis': float(stats.kurtosis(ret)),
        'max_drawdown': float((ret.cumsum() - ret.cumsum().cummax()).min())
    }

stats_df = pd.DataFrame(stats_dict).T
stats_df.to_csv('stock_statistics.csv')
print(f"‚úì Computed statistics for {len(stats_dict)} stocks")

# ============================================================================
# SECTION 4: SECTOR ANALYSIS & ROTATION
# ============================================================================

print("\n[5/15] Analyzing sector performance and rotation...")

# Group stocks by sector
sector_stocks = {}
for stock in stocks:
    sector = fundamentals_df.loc[stock, 'sector']
    if sector not in sector_stocks:
        sector_stocks[sector] = []
    sector_stocks[sector].append(stock)

# Calculate sector returns
sector_returns = {}
sector_momentum = {}

for sector, stock_list in sector_stocks.items():
    if len(stock_list) == 0:
        continue
    
    # Equal-weighted sector return
    sector_ret = returns[stock_list].mean(axis=1)
    sector_returns[sector] = sector_ret
    
    # Sector momentum (multiple timeframes)
    sector_momentum[sector] = {
        '5d': float(sector_ret.tail(5).sum() * 100),
        '20d': float(sector_ret.tail(20).sum() * 100),
        '60d': float(sector_ret.tail(60).sum() * 100),
        'ytd': float(sector_ret[sector_ret.index.year == datetime.now().year].sum() * 100)
    }

sector_returns_df = pd.DataFrame(sector_returns)
sector_momentum_df = pd.DataFrame(sector_momentum).T
sector_momentum_df.to_csv('sector_momentum.csv')

print("\nSector Performance (Last 20 Days):")
print(sector_momentum_df['20d'].sort_values(ascending=False).to_string())

# Sector rotation signal
sector_scores = {}
for sector in sector_momentum:
    # Combine momentum across timeframes with weights
    score = (
        sector_momentum[sector]['5d'] * 0.3 +
        sector_momentum[sector]['20d'] * 0.4 +
        sector_momentum[sector]['60d'] * 0.3
    )
    sector_scores[sector] = score

sector_rankings = pd.Series(sector_scores).sort_values(ascending=False)
print(f"\n‚úì Top Sector: {sector_rankings.index[0]} ({sector_rankings.iloc[0]:.2f}%)")

# ============================================================================
# SECTION 5: REGIME DETECTION
# ============================================================================

print("\n[6/15] Detecting market regimes...")

# Market-wide regime detection using S&P 500
try:
    spy_ret = spy_returns * 100
    
    model = MarkovRegression(
        spy_ret,
        k_regimes=3,  # Bull, Bear, Neutral
        switching_variance=True
    )
    
    res = model.fit(maxiter=100, disp=False, warn_convergence=False)
    smoothed_probs = res.smoothed_marginal_probabilities
    current_regime_probs = smoothed_probs.iloc[-1].values
    
    market_regime = {
        'current_regime': int(np.argmax(current_regime_probs)),
        'bull_prob': float(current_regime_probs[0]),
        'neutral_prob': float(current_regime_probs[1]),
        'bear_prob': float(current_regime_probs[2]),
        'regime_vols': [float(np.sqrt(res.params[f'sigma2[{i}]']) / 100) for i in range(3)]
    }
    
    regime_names = ['Bull', 'Neutral', 'Bear']
    current_regime_name = regime_names[market_regime['current_regime']]
    
    print(f"‚úì Market Regime: {current_regime_name}")
    print(f"  Bull: {market_regime['bull_prob']:.1%}, Neutral: {market_regime['neutral_prob']:.1%}, Bear: {market_regime['bear_prob']:.1%}")
    
except Exception as e:
    print(f"Note: Regime detection using simpler method: {e}")
    # Fallback: use VIX or volatility clustering
    vol_20d = spy_returns.rolling(20).std()
    vol_60d = spy_returns.rolling(60).std()
    
    current_vol = vol_20d.iloc[-1]
    avg_vol = vol_60d.iloc[-1]
    
    if current_vol > avg_vol * 1.5:
        market_regime = {'current_regime': 2, 'bear_prob': 0.7}
        current_regime_name = 'Bear'
    elif current_vol < avg_vol * 0.7:
        market_regime = {'current_regime': 0, 'bull_prob': 0.7}
        current_regime_name = 'Bull'
    else:
        market_regime = {'current_regime': 1, 'neutral_prob': 0.7}
        current_regime_name = 'Neutral'

# Save regime info
with open('market_regime.json', 'w') as f:
    json.dump(market_regime, f, indent=2)

# ============================================================================
# SECTION 6: VOLATILITY FORECASTING
# ============================================================================

print("\n[7/15] Forecasting volatility with GARCH models...")

from arch import arch_model

vol_forecasts = {}
vol_regime_adjusted = {}

for stock in stocks[:50]:  # Top 50 for speed
    try:
        series = returns[stock] * 100
        
        # Try multiple GARCH specifications
        models = []
        
        # GARCH(1,1) with Student-t
        try:
            m1 = arch_model(series, vol='Garch', p=1, q=1, dist='t', rescale=False)
            r1 = m1.fit(disp='off', show_warning=False)
            models.append(r1)
        except:
            pass
        
        # EGARCH(1,1) with Student-t
        try:
            m2 = arch_model(series, vol='EGARCH', p=1, q=1, dist='t', rescale=False)
            r2 = m2.fit(disp='off', show_warning=False)
            models.append(r2)
        except:
            pass
        
        # GJR-GARCH(1,1,1)
        try:
            m3 = arch_model(series, vol='Garch', p=1, o=1, q=1, dist='t', rescale=False)
            r3 = m3.fit(disp='off', show_warning=False)
            models.append(r3)
        except:
            pass
        
        if models:
            best = min(models, key=lambda r: r.aic)
            fcast = best.forecast(horizon=1)
            vol_forecasts[stock] = float(np.sqrt(fcast.variance.values[-1, 0]) / 100)
        else:
            vol_forecasts[stock] = float(series.std() / 100)
        
        # Regime adjustment
        beta = fundamentals_df.loc[stock, 'beta']
        if market_regime['current_regime'] == 2:  # Bear market
            regime_mult = 1.3
        elif market_regime['current_regime'] == 0:  # Bull market
            regime_mult = 0.9
        else:  # Neutral
            regime_mult = 1.0
        
        vol_regime_adjusted[stock] = vol_forecasts[stock] * regime_mult * beta
        
    except Exception as e:
        vol_forecasts[stock] = 0.02
        vol_regime_adjusted[stock] = 0.02

# For remaining stocks, use historical volatility
for stock in stocks:
    if stock not in vol_forecasts:
        vol_forecasts[stock] = float(returns[stock].std())
        beta = fundamentals_df.loc[stock, 'beta']
        regime_mult = 1.3 if market_regime['current_regime'] == 2 else (0.9 if market_regime['current_regime'] == 0 else 1.0)
        vol_regime_adjusted[stock] = vol_forecasts[stock] * regime_mult * beta

pd.DataFrame({'garch_vol': vol_forecasts, 'regime_adjusted': vol_regime_adjusted}).to_csv('volatility_forecasts.csv')
print(f"‚úì Forecasted volatility for {len(vol_forecasts)} stocks")

# ============================================================================
# SECTION 7: FACTOR MODELS & STYLE ANALYSIS
# ============================================================================

print("\n[8/15] Computing factor exposures...")

# Fama-French style factors (Value, Growth, Momentum, Quality, Size)
factor_exposures = {}

for stock in stocks:
    fund = fundamentals_df.loc[stock]
    
    # Value factor (lower P/E, P/B is better)
    value_score = 0
    if not pd.isna(fund['pe_ratio']) and fund['pe_ratio'] > 0:
        value_score += (1 / fund['pe_ratio']) * 100
    if not pd.isna(fund['price_to_book']) and fund['price_to_book'] > 0:
        value_score += (1 / fund['price_to_book']) * 100
    
    # Growth factor (revenue growth, earnings growth)
    growth_score = (
        fund['revenue_growth'] * 0.4 +
        fund['earnings_growth'] * 0.6
    )
    
    # Momentum factor (recent returns)
    momentum_score = float(returns[stock].tail(60).sum() * 100)
    
    # Quality factor (ROE, profit margins, low debt)
    quality_score = (
        fund['roe'] * 0.4 +
        fund['profit_margin'] * 0.3 +
        (100 - fund['debt_to_equity'] if not pd.isna(fund['debt_to_equity']) else 50) * 0.3
    )
    
    # Size factor (market cap, log scale)
    size_score = np.log10(fund['market_cap']) if fund['market_cap'] > 0 else 0
    
    factor_exposures[stock] = {
        'value': value_score,
        'growth': growth_score,
        'momentum': momentum_score,
        'quality': quality_score,
        'size': size_score
    }

factors_df = pd.DataFrame(factor_exposures).T
factors_df.to_csv('factor_exposures.csv')

# Standardize factors for scoring
scaler = StandardScaler()
factors_scaled = pd.DataFrame(
    scaler.fit_transform(factors_df.fillna(0)),
    index=factors_df.index,
    columns=factors_df.columns
)

print(f"‚úì Computed factor exposures for {len(factor_exposures)} stocks")

# ============================================================================
# SECTION 8: TECHNICAL INDICATORS
# ============================================================================

print("\n[9/15] Computing technical indicators...")

technical_indicators = {}

for stock in stocks:
    price = prices_df[stock].dropna()
    ret = returns[stock].dropna()
    
    # RSI (14-day)
    try:
        delta = price.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = float(100 - (100 / (1 + rs.iloc[-1])))
    except:
        rsi = 50.0
    
    # MACD
    try:
        ema_12 = price.ewm(span=12).mean()
        ema_26 = price.ewm(span=26).mean()
        macd = ema_12 - ema_26
        signal = macd.ewm(span=9).mean()
        macd_hist = float(macd.iloc[-1] - signal.iloc[-1])
    except:
        macd_hist = 0.0
    
    # Bollinger Bands
    try:
        sma_20 = price.rolling(20).mean()
        std_20 = price.rolling(20).std()
        bb_position = float((price.iloc[-1] - (sma_20.iloc[-1] - 2*std_20.iloc[-1])) / (4*std_20.iloc[-1]))
    except:
        bb_position = 0.5
    
    # Distance from 52-week high/low
    high_52w = fundamentals_df.loc[stock, '52w_high']
    low_52w = fundamentals_df.loc[stock, '52w_low']
    current_price = float(price.iloc[-1])
    
    if not pd.isna(high_52w) and high_52w > 0:
        dist_from_high = ((high_52w - current_price) / high_52w) * 100
    else:
        dist_from_high = 0
    
    if not pd.isna(low_52w) and low_52w > 0:
        dist_from_low = ((current_price - low_52w) / low_52w) * 100
    else:
        dist_from_low = 0
    
    # Average True Range (ATR)
    try:
        high = yf.Ticker(stock).history(period='3mo')['High']
        low = yf.Ticker(stock).history(period='3mo')['Low']
        close = yf.Ticker(stock).history(period='3mo')['Close']
        
        tr1 = high - low
        tr2 = abs(high - close.shift(1))
        tr3 = abs(low - close.shift(1))
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = float(tr.rolling(14).mean().iloc[-1])
        atr_pct = (atr / current_price) * 100
    except:
        atr_pct = 2.0
    
    technical_indicators[stock] = {
        'rsi': rsi,
        'macd_hist': macd_hist,
        'bb_position': bb_position,
        'dist_from_52w_high': dist_from_high,
        'dist_from_52w_low': dist_from_low,
        'atr_pct': atr_pct
    }

tech_df = pd.DataFrame(technical_indicators).T
tech_df.to_csv('technical_indicators.csv')
print(f"‚úì Computed technical indicators for {len(technical_indicators)} stocks")

# ============================================================================
# SECTION 9: MACHINE LEARNING PREDICTIONS
# ============================================================================

print("\n[10/15] Training ML models for return prediction...")

# Prepare features for ML
ml_features = {}

for stock in stocks:
    try:
        features = {
            # Fundamental features
            'pe_ratio': fundamentals_df.loc[stock, 'pe_ratio'],
            'peg_ratio': fundamentals_df.loc[stock, 'peg_ratio'],
            'price_to_book': fundamentals_df.loc[stock, 'price_to_book'],
            'dividend_yield': fundamentals_df.loc[stock, 'dividend_yield'],
            'profit_margin': fundamentals_df.loc[stock, 'profit_margin'],
            'roe': fundamentals_df.loc[stock, 'roe'],
            'revenue_growth': fundamentals_df.loc[stock, 'revenue_growth'],
            'earnings_growth': fundamentals_df.loc[stock, 'earnings_growth'],
            'beta': fundamentals_df.loc[stock, 'beta'],
            
            # Factor scores
            'value': factors_df.loc[stock, 'value'],
            'growth': factors_df.loc[stock, 'growth'],
            'momentum': factors_df.loc[stock, 'momentum'],
            'quality': factors_df.loc[stock, 'quality'],
            
            # Technical indicators
            'rsi': tech_df.loc[stock, 'rsi'],
            'macd_hist': tech_df.loc[stock, 'macd_hist'],
            'bb_position': tech_df.loc[stock, 'bb_position'],
            'dist_from_52w_high': tech_df.loc[stock, 'dist_from_52w_high'],
            
            # Risk metrics
            'volatility': stats_df.loc[stock, 'ann_volatility'],
            'sharpe': stats_df.loc[stock, 'sharpe_ratio'],
            'max_drawdown': stats_df.loc[stock, 'max_drawdown'],
            
            # Historical returns
            'ret_5d': float(returns[stock].tail(5).sum() * 100),
            'ret_20d': float(returns[stock].tail(20).sum() * 100),
            'ret_60d': float(returns[stock].tail(60).sum() * 100)
        }
        
        ml_features[stock] = features
    except Exception as e:
        continue

ml_df = pd.DataFrame(ml_features).T
ml_df = ml_df.replace([np.inf, -np.inf], np.nan).fillna(ml_df.median())

# Target: forward 20-day return
targets = {}
for stock in ml_df.index:
    # Use last 20 days as "future" for training, actual forecast for current
    forward_ret = returns[stock].tail(20).sum() * 100
    targets[stock] = float(forward_ret)

ml_df['target'] = pd.Series(targets)
ml_df_clean = ml_df.dropna()

# Train ensemble model
X = ml_df_clean.drop('target', axis=1)
y = ml_df_clean['target']

# Random Forest
rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
rf_model.fit(X, y)
rf_predictions = rf_model.predict(X)

# Gradient Boosting
gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)
gb_model.fit(X, y)
gb_predictions = gb_model.predict(X)

# Ensemble prediction (average)
ml_predictions = (rf_predictions + gb_predictions) / 2

ml_pred_df = pd.DataFrame({
    'rf_pred': rf_predictions,
    'gb_pred': gb_predictions,
    'ensemble_pred': ml_predictions
}, index=ml_df_clean.index)

ml_pred_df.to_csv('ml_predictions.csv')

# Feature importance
feature_importance = pd.Series(
    rf_model.feature_importances_,
    index=X.columns
).sort_values(ascending=False)

print("\nTop 10 Most Important Features:")
print(feature_importance.head(10).to_string())

print(f"‚úì Trained ML models on {len(ml_df_clean)} stocks")

# ============================================================================
# SECTION 10: EXPECTED RETURN CALCULATION
# ============================================================================

print("\n[11/15] Calculating expected returns...")

expected_returns = {}

for stock in stocks:
    if stock not in ml_df_clean.index:
        continue
    
    # Combine multiple signals
    
    # 1. ML prediction (20-day forward return)
    ml_signal = ml_pred_df.loc[stock, 'ensemble_pred']
    
    # 2. Momentum signal
    momentum_signal = factors_df.loc[stock, 'momentum']
    
    # 3. Sector momentum
    sector = fundamentals_df.loc[stock, 'sector']
    sector_signal = sector_scores.get(sector, 0)
    
    # 4. Technical signal
    tech_signal = (
        (tech_df.loc[stock, 'rsi'] - 50) / 50 * 5 +  # RSI deviation
        tech_df.loc[stock, 'macd_hist'] * 10  # MACD histogram
    )
    
    # 5. Factor composite
    factor_signal = (
        factors_scaled.loc[stock, 'value'] * 0.2 +
        factors_scaled.loc[stock, 'growth'] * 0.25 +
        factors_scaled.loc[stock, 'momentum'] * 0.25 +
        factors_scaled.loc[stock, 'quality'] * 0.3
    )
    
    # Weighted combination
    expected_return = (
        ml_signal * 0.35 +
        momentum_signal * 0.20 +
        sector_signal * 0.15 +
        tech_signal * 0.15 +
        factor_signal * 0.15
    )
    
    # Adjust for market regime
    if market_regime['current_regime'] == 2:  # Bear market
        expected_return *= 0.7  # Reduce expectations
    elif market_regime['current_regime'] == 0:  # Bull market
        expected_return *= 1.1  # Increase expectations
    
    expected_returns[stock] = {
        'expected_return_20d': expected_return,
        'ml_signal': ml_signal,
        'momentum_signal': momentum_signal,
        'sector_signal': sector_signal,
        'technical_signal': tech_signal,
        'factor_signal': factor_signal
    }

expected_returns_df = pd.DataFrame(expected_returns).T
expected_returns_df.to_csv('expected_returns.csv')
print(f"‚úì Calculated expected returns for {len(expected_returns)} stocks")

# ============================================================================
# SECTION 11: MONTE CARLO SIMULATION
# ============================================================================

print("\n[12/15] Running Monte Carlo simulations...")

def simulate_stock_price(S0, mu, sigma, beta, days=20, trials=3000,
                        market_regime='Neutral', jump_prob=0.03):
    """
    Advanced stock price simulation with:
    - Regime-dependent volatility
    - Jump diffusion for earnings/news shocks
    - Fat-tailed returns (Student-t)
    - Beta-adjusted market exposure
    """
    np.random.seed(42)
    
    # Regime adjustments
    if market_regime == 'Bear':
        vol_mult = 1.5
        drift_adjust = -0.002
    elif market_regime == 'Bull':
        vol_mult = 0.8
        drift_adjust = 0.001
    else:
        vol_mult = 1.0
        drift_adjust = 0.0
    
    sigma_adj = sigma * vol_mult * beta
    mu_adj = mu + drift_adjust
    
    results = []
    
    for _ in range(trials):
        price = S0
        
        for t in range(days):
            # Student-t distributed returns (df=5 for fat tails)
            eps = stats.t.rvs(df=5, size=1)[0] / np.sqrt(5/3)
            
            # Jump component (earnings surprises, news events)
            if np.random.rand() < jump_prob:
                # Jumps can be positive or negative
                jump = np.random.normal(0, 0.05)  # ¬±5% typical jump
            else:
                jump = 0
            
            # Geometric Brownian Motion with jumps
            drift_term = (mu_adj/days - 0.5 * sigma_adj**2)
            diffusion_term = sigma_adj * eps / np.sqrt(days)
            
            price *= np.exp(drift_term + diffusion_term + jump)
        
        results.append(price)
    
    return np.array(results)

# Run simulations for top stocks
sim_results = {}
horizons = {'1w': 5, '2w': 10, '1m': 20, '2m': 40, '3m': 60}

for horizon_name, days in horizons.items():
    if horizon_name != '1m':  # Focus on 1-month for speed
        continue
    
    print(f"  Simulating {horizon_name} horizon...")
    sim_results[horizon_name] = {}
    
    for stock in list(expected_returns_df.index)[:50]:  # Top 50
        try:
            S0 = float(prices_df[stock].iloc[-1])
            mu = expected_returns_df.loc[stock, 'expected_return_20d'] / 100  # Convert to fraction
            sigma = vol_regime_adjusted.get(stock, 0.02)
            beta = fundamentals_df.loc[stock, 'beta']
            
            # Run simulation
            final_prices = simulate_stock_price(
                S0, mu, sigma, beta,
                days=days, trials=3000,
                market_regime=current_regime_name,
                jump_prob=0.03
            )
            
            # Calculate statistics
            returns_sim = (final_prices / S0 - 1.0) * 100
            
            sim_results[horizon_name][stock] = {
                'current_price': S0,
                'mean_return': float(np.mean(returns_sim)),
                'median_return': float(np.median(returns_sim)),
                'std_return': float(np.std(returns_sim)),
                'p5': float(np.percentile(returns_sim, 5)),
                'p25': float(np.percentile(returns_sim, 25)),
                'p75': float(np.percentile(returns_sim, 75)),
                'p95': float(np.percentile(returns_sim, 95)),
                'VaR_95': float(-np.percentile(returns_sim, 5)),
                'CVaR_95': float(-np.mean(returns_sim[returns_sim <= np.percentile(returns_sim, 5)])),
                'prob_up': float(np.mean(final_prices > S0)),
                'expected_price': float(np.mean(final_prices)),
                'price_target_bull': float(np.percentile(final_prices, 75)),
                'price_target_bear': float(np.percentile(final_prices, 25)),
                'max_upside': float(np.percentile(returns_sim, 95)),
                'max_downside': float(np.percentile(returns_sim, 5))
            }
            
        except Exception as e:
            continue

# Save simulation results
for horizon_name in sim_results:
    pd.DataFrame(sim_results[horizon_name]).T.to_csv(f'sim_results_{horizon_name}.csv')

print(f"‚úì Completed simulations for {len(sim_results.get('1m', {}))} stocks")

# ============================================================================
# SECTION 12: RISK-ADJUSTED RANKING
# ============================================================================

print("\n[13/15] Computing risk-adjusted rankings...")

def calculate_risk_metrics(stock, sim_data, expected_ret):
    """Calculate comprehensive risk-adjusted performance metrics"""
    
    if stock not in sim_data:
        return None
    
    stats_sim = sim_data[stock]
    
    # Sharpe Ratio (annualized)
    sharpe = (stats_sim['mean_return'] / stats_sim['std_return'] * np.sqrt(252/20)) if stats_sim['std_return'] > 0 else 0
    
    # Sortino Ratio (downside deviation only)
    downside_returns = np.array([r for r in np.random.normal(stats_sim['mean_return'], stats_sim['std_return'], 1000) if r < 0])
    downside_std = np.std(downside_returns) if len(downside_returns) > 0 else 1
    sortino = stats_sim['mean_return'] / downside_std if downside_std > 0 else 0
    
    # Information Ratio (vs SPY)
    tracking_error = vol_regime_adjusted.get(stock, 0.02) * 100
    spy_expected = 0.5  # Assume SPY ~0.5% monthly in current regime
    information_ratio = (stats_sim['mean_return'] - spy_expected) / tracking_error if tracking_error > 0 else 0
    
    # Calmar Ratio (return / max drawdown)
    max_dd = abs(stats_df.loc[stock, 'max_drawdown']) if stock in stats_df.index else 10
    calmar = stats_sim['mean_return'] / max_dd if max_dd > 0 else 0
    
    # Omega Ratio
    gains = max(stats_sim['mean_return'], 0)
    losses = abs(min(stats_sim['mean_return'], 0))
    omega = (gains / losses) if losses > 0 else float('inf') if gains > 0 else 0
    
    # Return to VaR
    return_to_var = stats_sim['mean_return'] / stats_sim['VaR_95'] if stats_sim['VaR_95'] > 0 else 0
    
    # Composite score (weighted combination)
    composite_score = (
        sharpe * 0.25 +
        sortino * 0.20 +
        information_ratio * 0.15 +
        calmar * 0.15 +
        min(omega, 10) * 0.10 +  # Cap omega at 10
        return_to_var * 0.15
    )
    
    return {
        'sharpe_ratio': sharpe,
        'sortino_ratio': sortino,
        'information_ratio': information_ratio,
        'calmar_ratio': calmar,
        'omega_ratio': omega,
        'return_to_var': return_to_var,
        'composite_score': composite_score
    }

# Calculate rankings
rankings = {}

for stock in sim_results.get('1m', {}):
    metrics = calculate_risk_metrics(
        stock,
        sim_results['1m'],
        expected_returns_df.loc[stock, 'expected_return_20d']
    )
    
    if metrics is None:
        continue
    
    sim_data = sim_results['1m'][stock]
    
    rankings[stock] = {
        'expected_return': sim_data['mean_return'],
        'volatility': stats_df.loc[stock, 'ann_volatility'] if stock in stats_df.index else np.nan,
        'prob_profitable': sim_data['prob_up'],
        'VaR_95': sim_data['VaR_95'],
        'CVaR_95': sim_data['CVaR_95'],
        'max_upside': sim_data['max_upside'],
        'max_downside': sim_data['max_downside'],
        'sharpe': metrics['sharpe_ratio'],
        'sortino': metrics['sortino_ratio'],
        'information_ratio': metrics['information_ratio'],
        'composite_score': metrics['composite_score'],
        'sector': fundamentals_df.loc[stock, 'sector'],
        'market_cap_b': fundamentals_df.loc[stock, 'market_cap'] / 1e9,
        'pe_ratio': fundamentals_df.loc[stock, 'pe_ratio'],
        'dividend_yield': fundamentals_df.loc[stock, 'dividend_yield'],
        'beta': fundamentals_df.loc[stock, 'beta'],
        'current_price': sim_data['current_price'],
        'price_target': sim_data['expected_price']
    }

rankings_df = pd.DataFrame(rankings).T
rankings_df = rankings_df.sort_values('composite_score', ascending=False)
rankings_df.to_csv('stock_rankings_comprehensive.csv')

print("\n" + "=" * 80)
print("TOP 20 STOCKS BY RISK-ADJUSTED SCORE (1-Month Horizon)")
print("=" * 80)
display_cols = ['expected_return', 'sharpe', 'prob_profitable', 'composite_score', 'sector']
print(rankings_df[display_cols].head(20).to_string())

# ============================================================================
# SECTION 13: PORTFOLIO CONSTRUCTION
# ============================================================================

print("\n[14/15] Constructing optimal portfolios...")

def construct_portfolio(rankings_df, n_stocks=20, diversify_sectors=True):
    """Construct portfolio with diversification constraints"""
    
    portfolio = []
    sector_counts = {}
    max_per_sector = 5 if diversify_sectors else n_stocks
    
    for stock, row in rankings_df.iterrows():
        if len(portfolio) >= n_stocks:
            break
        
        sector = row['sector']
        sector_count = sector_counts.get(sector, 0)
        
        if sector_count < max_per_sector:
            portfolio.append(stock)
            sector_counts[sector] = sector_count + 1
    
    return portfolio

# Construct different portfolio strategies
portfolios = {}

# 1. Growth Portfolio (high expected return)
growth_portfolio = construct_portfolio(
    rankings_df.sort_values('expected_return', ascending=False),
    n_stocks=15
)

# 2. Quality Portfolio (high Sharpe ratio)
quality_portfolio = construct_portfolio(
    rankings_df.sort_values('sharpe', ascending=False),
    n_stocks=15
)

# 3. Balanced Portfolio (high composite score)
balanced_portfolio = construct_portfolio(
    rankings_df.sort_values('composite_score', ascending=False),
    n_stocks=20
)

# 4. Defensive Portfolio (low beta, high dividend yield)
defensive_df = rankings_df[rankings_df['beta'] < 1.0].sort_values('dividend_yield', ascending=False)
defensive_portfolio = construct_portfolio(defensive_df, n_stocks=15)

# 5. Momentum Portfolio (high recent returns)
momentum_df = rankings_df.sort_values('expected_return', ascending=False)
momentum_portfolio = construct_portfolio(momentum_df, n_stocks=15)

portfolios = {
    'Growth': growth_portfolio,
    'Quality': quality_portfolio,
    'Balanced': balanced_portfolio,
    'Defensive': defensive_portfolio,
    'Momentum': momentum_portfolio
}

# Calculate portfolio metrics
portfolio_metrics = {}

for portfolio_name, stocks in portfolios.items():
    portfolio_returns = expected_returns_df.loc[stocks, 'expected_return_20d'].mean()
    portfolio_vol = np.sqrt(np.mean([vol_regime_adjusted.get(s, 0.02)**2 for s in stocks])) * 100 * np.sqrt(252)
    portfolio_sharpe = portfolio_returns / (portfolio_vol / np.sqrt(252/20)) if portfolio_vol > 0 else 0
    
    sectors_in_portfolio = fundamentals_df.loc[stocks, 'sector'].value_counts()
    
    portfolio_metrics[portfolio_name] = {
        'expected_return_20d': portfolio_returns,
        'ann_volatility': portfolio_vol,
        'sharpe_ratio': portfolio_sharpe,
        'n_stocks': len(stocks),
        'n_sectors': len(sectors_in_portfolio),
        'top_sector': sectors_in_portfolio.index[0] if len(sectors_in_portfolio) > 0 else 'N/A',
        'avg_market_cap_b': fundamentals_df.loc[stocks, 'market_cap'].mean() / 1e9
    }

portfolio_metrics_df = pd.DataFrame(portfolio_metrics).T
portfolio_metrics_df.to_csv('portfolio_strategies.csv')

print("\nPortfolio Strategy Comparison:")
print(portfolio_metrics_df[['expected_return_20d', 'sharpe_ratio', 'n_stocks', 'n_sectors']].to_string())

# Save detailed portfolio holdings
for portfolio_name, stocks in portfolios.items():
    holdings_df = rankings_df.loc[stocks, ['expected_return', 'sharpe', 'sector', 'current_price', 'price_target']]
    holdings_df.to_csv(f'portfolio_{portfolio_name.lower()}_holdings.csv')

# ============================================================================
# SECTION 14: ACTIONABLE RECOMMENDATIONS
# ============================================================================

print("\n" + "=" * 80)
print("TOP TRADING OPPORTUNITIES")
print("=" * 80)

# Best overall picks
top_10 = rankings_df.head(10)

print("\nüèÜ TOP 10 STOCKS (Risk-Adjusted):\n")
for i, (stock, row) in enumerate(top_10.iterrows(), 1):
    print(f"{i}. {stock} ({row['sector']})")
    print(f"   Current Price: ${row['current_price']:.2f}")
    print(f"   Price Target (1M): ${row['price_target']:.2f} ({row['expected_return']:.2f}%)")
    print(f"   Probability Up: {row['prob_profitable']:.1%}")
    print(f"   Sharpe Ratio: {row['sharpe']:.2f}")
    print(f"   Max Upside: {row['max_upside']:.2f}% | Max Downside: {row['max_downside']:.2f}%")
    print()

# Sector leaders
print("\nüìä BEST STOCK IN EACH SECTOR:\n")
sector_leaders = {}
for sector in rankings_df['sector'].unique():
    sector_stocks = rankings_df[rankings_df['sector'] == sector]
    if not sector_stocks.empty:
        leader = sector_stocks.iloc[0]
        sector_leaders[sector] = leader.name
        print(f"{sector}: {leader.name}")
        print(f"   Expected Return: {leader['expected_return']:.2f}%")
        print(f"   Composite Score: {leader['composite_score']:.2f}")
        print()

# High-conviction picks (high probability + high return)
high_conviction = rankings_df[
    (rankings_df['prob_profitable'] > 0.65) & 
    (rankings_df['expected_return'] > 3.0)
].sort_values('composite_score', ascending=False)

if not high_conviction.empty:
    print("\nüíé HIGH-CONVICTION PICKS (>65% Win Rate, >3% Expected Return):\n")
    for stock, row in high_conviction.head(5).iterrows():
        print(f"{stock}: {row['expected_return']:.2f}% ({row['prob_profitable']:.1%} win rate)")

# Contrarian opportunities (oversold with good fundamentals)
contrarian = rankings_df[
    (rankings_df['expected_return'] > 2.0) &
    (tech_df.loc[rankings_df.index, 'rsi'] < 40)
].sort_values('composite_score', ascending=False)

if not contrarian.empty:
    print("\nüîÑ CONTRARIAN OPPORTUNITIES (Oversold with Upside):\n")
    for stock, row in contrarian.head(5).iterrows():
        rsi = tech_df.loc[stock, 'rsi']
        print(f"{stock}: RSI={rsi:.1f}, Expected Return={row['expected_return']:.2f}%")

# Dividend aristocrats (high yield + positive momentum)
div_stocks = rankings_df[rankings_df['dividend_yield'] > 2.0].sort_values('dividend_yield', ascending=False)

if not div_stocks.empty:
    print("\nüí∞ TOP DIVIDEND PLAYS (>2% Yield):\n")
    for stock, row in div_stocks.head(5).iterrows():
        print(f"{stock}: {row['dividend_yield']:.2f}% yield, {row['expected_return']:.2f}% expected return")

# ============================================================================
# SECTION 15: RISK WARNINGS & BACKTEST TRACKING
# ============================================================================

print("\n" + "=" * 80)
print("RISK MANAGEMENT & TRACKING")
print("=" * 80)

# Risk warnings
print("\n‚ö†Ô∏è  RISK WARNINGS:\n")

high_risk_stocks = rankings_df[
    (rankings_df['volatility'] > 40) | 
    (rankings_df['VaR_95'] > 10)
].sort_values('VaR_95', ascending=False)

if not high_risk_stocks.empty:
    print("High Risk Stocks (>40% Ann. Vol or >10% VaR):")
    for stock, row in high_risk_stocks.head(5).iterrows():
        print(f"  {stock}: Vol={row['volatility']:.1f}%, VaR={row['VaR_95']:.2f}%")

# Suggested stop losses and take profits
print("\nüéØ SUGGESTED STOP LOSSES & TAKE PROFITS (Top 5):\n")
for stock, row in rankings_df.head(5).iterrows():
    current = row['current_price']
    var_95 = row['VaR_95'] / 100
    upside_75 = row['max_upside'] / 100
    
    stop_loss = current * (1 - var_95)
    take_profit = current * (1 + upside_75 * 0.7)  # 70% of max upside
    
    print(f"{stock}:")
    print(f"  Current: ${current:.2f}")
    print(f"  Stop Loss (95% VaR): ${stop_loss:.2f} (-{var_95*100:.1f}%)")
    print(f"  Take Profit (70% of max): ${take_profit:.2f} (+{(take_profit/current-1)*100:.1f}%)")
    print()

# Backtest tracking
try:
    bt_file = 'stock_forecast_backtest.csv'
    today_stamp = pd.Timestamp.utcnow().normalize()
    
    bt_rows = []
    for stock in rankings_df.index:
        bt_rows.append({
            'date': str(today_stamp.date()),
            'ticker': stock,
            'current_price': rankings_df.loc[stock, 'current_price'],
            'forecast_return_1m': rankings_df.loc[stock, 'expected_return'],
            'forecast_price_target': rankings_df.loc[stock, 'price_target'],
            'prob_up': rankings_df.loc[stock, 'prob_profitable'],
            'composite_score': rankings_df.loc[stock, 'composite_score'],
            'actual_return_1m': np.nan,
            'actual_price_1m': np.nan,
            'forecast_accuracy': np.nan
        })
    
    new_bt = pd.DataFrame(bt_rows)
    
    # Load and update existing backtest data
    try:
        old_bt = pd.read_csv(bt_file)
        
        # Fill in actual returns from 1 month ago
        one_month_ago = (today_stamp - pd.Timedelta(days=30)).date()
        mask_past = old_bt['date'] == str(one_month_ago)
        
        if mask_past.any():
            for stock in old_bt[mask_past]['ticker'].unique():
                if stock not in prices_df.columns:
                    continue
                
                try:
                    # Get actual 20-day return
                    price_then = old_bt.loc[mask_past & (old_bt['ticker'] == stock), 'current_price'].values[0]
                    price_now = prices_df[stock].iloc[-1]
                    actual_return = ((price_now - price_then) / price_then) * 100
                    
                    idx = old_bt.index[mask_past & (old_bt['ticker'] == stock)]
                    if len(idx) > 0:
                        forecast_ret = old_bt.loc[idx[0], 'forecast_return_1m']
                        old_bt.loc[idx, 'actual_return_1m'] = actual_return
                        old_bt.loc[idx, 'actual_price_1m'] = price_now
                        
                        if not pd.isna(forecast_ret):
                            error = abs(actual_return - forecast_ret)
                            old_bt.loc[idx, 'forecast_accuracy'] = 100 - min(error, 100)
                except Exception:
                    pass
        
        bt_all = pd.concat([old_bt, new_bt], ignore_index=True)
    except FileNotFoundError:
        bt_all = new_bt
    
    bt_all = bt_all.drop_duplicates(subset=['date', 'ticker'], keep='last')
    bt_all.to_csv(bt_file, index=False)
    
    # Calculate overall accuracy
    completed = bt_all.dropna(subset=['forecast_return_1m', 'actual_return_1m'])
    
    if len(completed) > 0:
        mae = abs(completed['forecast_return_1m'] - completed['actual_return_1m']).mean()
        rmse = np.sqrt(((completed['forecast_return_1m'] - completed['actual_return_1m'])**2).mean())
        
        direction_correct = (
            np.sign(completed['forecast_return_1m']) == np.sign(completed['actual_return_1m'])
        ).mean()
        
        avg_accuracy = completed['forecast_accuracy'].mean()
        
        print("\nüìà Historical Forecast Performance:")
        print(f"   Forecasts Tracked: {len(completed)}")
        print(f"   Mean Absolute Error: {mae:.2f}%")
        print(f"   Root Mean Squared Error: {rmse:.2f}%")
        print(f"   Direction Accuracy: {direction_correct:.1%}")
        print(f"   Average Accuracy Score: {avg_accuracy:.1f}/100")
        
        # Save accuracy metrics
        pd.DataFrame([{
            'date': str(today_stamp.date()),
            'n_forecasts': len(completed),
            'mae': mae,
            'rmse': rmse,
            'direction_accuracy': direction_correct,
            'avg_accuracy_score': avg_accuracy
        }]).to_csv('forecast_performance_history.csv', mode='a', header=not pd.io.common.file_exists('forecast_performance_history.csv'), index=False)

except Exception as e:
    print(f"Note: Backtest tracking error: {e}")

# ============================================================================
# FINAL: EXPORT COMPREHENSIVE REPORTS
# ============================================================================

print("\n" + "=" * 80)
print("GENERATING COMPREHENSIVE REPORTS")
print("=" * 80)

# Summary report
summary_report = {
    'analysis_date': datetime.utcnow().isoformat(),
    'market_regime': current_regime_name,
    'stocks_analyzed': len(stocks),
    'top_sector': sector_rankings.index[0],
    'top_stock': rankings_df.index[0],
    'top_stock_expected_return': float(rankings_df.iloc[0]['expected_return']),
    'avg_expected_return': float(rankings_df['expected_return'].mean()),
    'portfolios_generated': len(portfolios)
}

with open('analysis_summary.json', 'w') as f:
    json.dump(summary_report, f, indent=2)

# Metadata
metadata = {
    'timestamp_utc': pd.Timestamp.utcnow().isoformat(),
    'python_version': sys.version.split()[0],
    'stocks_analyzed': len(stocks),
    'simulation_trials': 3000,
    'horizons': list(horizons.keys()),
    'ml_models': ['Random Forest', 'Gradient Boosting'],
    'volatility_models': ['GARCH', 'EGARCH', 'GJR-GARCH'],
    'market_regime': current_regime_name,
    'data_sources': ['Yahoo Finance', 'Wikipedia S&P 500 List']
}

with open('run_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)

print("\n‚úÖ Analysis complete! Generated files:")
print("   - sp500_fundamentals.csv")
print("   - stock_statistics.csv")
print("   - sector_momentum.csv")
print("   - volatility_forecasts.csv")
print("   - factor_exposures.csv")
print("   - technical_indicators.csv")
print("   - ml_predictions.csv")
print("   - expected_returns.csv")
print("   - sim_results_1m.csv")
print("   - stock_rankings_comprehensive.csv")
print("   - portfolio_strategies.csv")
print("   - portfolio_*_holdings.csv (5 strategies)")
print("   - stock_forecast_backtest.csv")
print("   - analysis_summary.json")
print("   - run_metadata.json")

print("\n" + "=" * 80)
print("S&P 500 STOCK FORECASTING SYSTEM - COMPLETE")
print("=" * 80)
print(f"\nüéØ Recommended Action: Review '{rankings_df.index[0]}' for potential entry")
print(f"üìä Market Regime: {current_regime_name}")
print(f"üèÜ Best Portfolio Strategy: {portfolio_metrics_df['sharpe_ratio'].idxmax()}")
print("\nHappy Trading! üöÄ")

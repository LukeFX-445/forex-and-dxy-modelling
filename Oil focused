# ============================================================
# Multi-Asset Macro-Quant Forecasting System V3 (Oil-First)
# COLAB-NATIVE SAFE VERSION (NO CORE DOWNGRADES)
# - Keeps Colab NumPy2 / Pandas2.2+ / SciPy / Sklearn
# - arch OPTIONAL (fallback vol used if arch incompatible)
# - lightgbm OPTIONAL (skip if build/import fails)
# - FIX: macro string features encoded to numeric
# - FIX: CSV saving uses stdlib ONLY (avoids pandas internals)
# ============================================================

import warnings
warnings.filterwarnings("ignore")

# ----------------------------
# 0) COLAB-NATIVE INSTALL CELL
# ----------------------------
!pip install -q --upgrade pip
!pip install -q yfinance statsmodels xgboost vaderSentiment feedparser

# Optional: lightgbm (may fail to build on some Colab images)
LGB_AVAILABLE, _lgb_err = False, None
try:
    !pip install -q lightgbm
    import lightgbm as lgb
    LGB_AVAILABLE = True
except Exception as e:
    _lgb_err = e
    LGB_AVAILABLE = False

# Optional: arch (often incompatible with NumPy2 -> fallback vol will be used)
ARCH_AVAILABLE, _arch_err = False, None
try:
    !pip install -q arch
    from arch import arch_model
    ARCH_AVAILABLE = True
except Exception as e:
    _arch_err = e
    ARCH_AVAILABLE = False

print("‚úÖ Colab core stack (left untouched).")
import numpy as np, pandas as pd, scipy, sklearn
print("numpy:", np.__version__, "| pandas:", pd.__version__, "| scipy:", scipy.__version__, "| sklearn:", sklearn.__version__)
print("arch available:", ARCH_AVAILABLE, "| lightgbm available:", LGB_AVAILABLE)
if _arch_err: print("arch import/install error:", _arch_err)
if _lgb_err: print("lgb import/install error:", _lgb_err)

# ----------------------------
# 1) IMPORTS
# ----------------------------
import yfinance as yf
from datetime import datetime, timedelta
from scipy import stats

from sklearn.preprocessing import RobustScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score

from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression
import xgboost as xgb

# ----------------------------
# 2) CONFIG
# ----------------------------
SEED = 42
np.random.seed(SEED)

END_DATE = datetime.utcnow()
START_DATE = END_DATE - timedelta(days=6 * 365)

ASSETS = {
    "SPY": "S&P 500 ETF",
    "QQQ": "NASDAQ-100 ETF",
    "CL=F": "WTI Crude Oil Futures",
    "GLD": "Gold ETF"
}

ASSET_BACKUPS = {"CL=F": ["BZ=F"]}

INDICATORS = {
    "^VIX": "VIX",
    "^TNX": "10Y Treasury Yield",
    "DX-Y.NYB": "DXY",
    "HYG": "High Yield Credit",
    "LQD": "Inv Grade Credit",
    "XLE": "Energy Sector",
    "UNG": "Nat Gas ETF",
    "NG=F": "Nat Gas Futures",
    "XOP": "E&P ETF",
    "OIH": "Oil Services ETF",
    "EEM": "EM Equities",
    "IWM": "US Small Caps",
    "BZ=F": "Brent Futures"
}

HORIZONS = {"1d":1, "3d":3, "5d":5, "10d":10, "20d":20}
DIR_BINS   = [-np.inf, -0.5, 0.5, np.inf]
DIR_LABELS = [-1, 0, 1]

# ----------------------------
# 3) UTILITIES
# ----------------------------
def download_single(ticker):
    data = yf.download(ticker, start=START_DATE, end=END_DATE,
                       progress=False, auto_adjust=False)
    if isinstance(data.columns, pd.MultiIndex):
        data = data.xs(ticker, axis=1, level=1)
    return data

def safe_pct_change(x, n=1):
    return x.pct_change(n).replace([np.inf, -np.inf], np.nan)

def zscore(series, window):
    mu = series.rolling(window).mean()
    sig = series.rolling(window).std()
    return (series - mu) / sig.replace(0, np.nan)

def winsorize_series(s, p=0.01):
    lo, hi = s.quantile(p), s.quantile(1-p)
    return s.clip(lo, hi)

def extract_ohlcv(data_dict):
    closes, opens, highs, lows, volumes = {}, {}, {}, {}, {}
    for tkr, d in data_dict.items():
        if "Close" in d: closes[tkr] = d["Close"]
        if "Open"  in d: opens[tkr]  = d["Open"]
        if "High"  in d: highs[tkr]  = d["High"]
        if "Low"   in d: lows[tkr]   = d["Low"]
        if "Volume" in d: volumes[tkr] = d["Volume"]
    return (pd.DataFrame(closes),
            pd.DataFrame(opens),
            pd.DataFrame(highs),
            pd.DataFrame(lows),
            pd.DataFrame(volumes))

# ----------------------------
# 4) DATA COLLECTION
# ----------------------------
def collect_market_data():
    asset_data, failed = {}, []

    for tkr in ASSETS:
        try:
            d = download_single(tkr)
            if not d.empty and len(d) > 150:
                asset_data[tkr] = d
            else:
                failed.append(tkr)
        except Exception:
            failed.append(tkr)

    for ftkr in failed:
        if ftkr in ASSET_BACKUPS:
            for btkr in ASSET_BACKUPS[ftkr]:
                try:
                    d = download_single(btkr)
                    if not d.empty and len(d) > 150:
                        asset_data[ftkr] = d
                        break
                except Exception:
                    continue

    indicator_data = {}
    for tkr in INDICATORS:
        try:
            d = download_single(tkr)
            if not d.empty and len(d) > 150:
                indicator_data[tkr] = d
        except Exception:
            continue

    return asset_data, indicator_data

# ----------------------------
# 5) MACRO PROXIES
# ----------------------------
def build_macro_indicators(asset_closes, indicator_closes):
    macro = {}

    if "^TNX" in indicator_closes:
        tnx = indicator_closes["^TNX"]
        macro["yield_10y"] = float(tnx.iloc[-1])
        macro["yield_10y_1m_change"] = float(tnx.diff(21).iloc[-1])
        macro["yield_10y_3m_change"] = float(tnx.diff(63).iloc[-1])

    if "DX-Y.NYB" in indicator_closes:
        dxy = indicator_closes["DX-Y.NYB"]
        macro["dxy_current"] = float(dxy.iloc[-1])
        macro["dxy_1m_change"] = float(dxy.diff(21).iloc[-1])
        macro["dxy_3m_change"] = float(dxy.diff(63).iloc[-1])
        macro["dxy_strength"] = "Strong" if dxy.iloc[-1] > dxy.rolling(200).mean().iloc[-1] else "Weak"

    if "^VIX" in indicator_closes:
        vix = indicator_closes["^VIX"]
        macro["vix_current"]  = float(vix.iloc[-1])
        macro["vix_20d_avg"]  = float(vix.rolling(20).mean().iloc[-1])
        macro["vix_spike"]    = bool(vix.iloc[-1] > vix.rolling(20).mean().iloc[-1] + vix.rolling(20).std().iloc[-1])

    if "HYG" in indicator_closes and "LQD" in indicator_closes:
        hyg = indicator_closes["HYG"]
        lqd = indicator_closes["LQD"]
        spread_proxy = hyg.pct_change(21).iloc[-1] - lqd.pct_change(21).iloc[-1]
        macro["credit_spread_proxy"] = float(spread_proxy)
        macro["credit_stress"]       = bool(spread_proxy < -0.03)

    macro["liquidity_proxy"] = "High" if (macro.get("credit_stress") is False and
                                          macro.get("vix_current", 20) < 20) else "Normal"
    macro["equity_risk_premium"] = 2.5

    inv_curve = macro.get("yield_10y",0) < 3.0 and macro.get("credit_stress",False)
    if inv_curve or macro.get("vix_current",15) > 30:
        macro["recession_risk"]    = "High"
        macro["recession_signals"] = ["Credit stress", "Vol spike"]
    else:
        macro["recession_risk"]    = "Low"
        macro["recession_signals"] = ["None"]

    if "CL=F" in asset_closes:
        oil_ret = asset_closes["CL=F"].pct_change().dropna()
        macro["oil_volatility_60d"] = float(oil_ret.rolling(60).std().iloc[-1] * np.sqrt(252) * 100)

    return macro


# ----------------------------
# 6) TARGETS
# ----------------------------
def make_targets(asset_closes):
    targets = {}
    for tkr in ASSETS:
        price = asset_closes[tkr]
        tdf = {}
        for hname, d in HORIZONS.items():
            fwd = price.pct_change(d).shift(-d) * 100
            tdf[f"{hname}_direction"] = pd.cut(fwd, DIR_BINS, labels=DIR_LABELS).astype(float)
            tdf[f"{hname}_binary"]    = (fwd > 0).astype(int)
            tdf[f"{hname}_return"]    = fwd / 100.0
        targets[tkr] = pd.DataFrame(tdf, index=price.index)
    return targets

# ----------------------------
# 7) VOL (arch optional)
# ----------------------------
def _fit_best_arch(r):
    r = r.dropna() * 100.0
    candidates = []
    specs = [
        ("GARCH","normal", dict(vol="GARCH",p=1,q=1,o=0,dist="normal")),
        ("GARCH","t",      dict(vol="GARCH",p=1,q=1,o=0,dist="t")),
        ("EGARCH","normal",dict(vol="EGARCH",p=1,q=1,o=0,dist="normal")),
        ("EGARCH","t",      dict(vol="EGARCH",p=1,q=1,o=0,dist="t")),
        ("GJR","normal",   dict(vol="GARCH",p=1,q=1,o=1,dist="normal")),
        ("GJR","t",        dict(vol="GARCH",p=1,q=1,o=1,dist="t")),
    ]
    for name, dist, kw in specs:
        try:
            am = arch_model(r, mean="Zero", **kw)
            res = am.fit(disp="off")
            candidates.append((res.aic,name,dist,res))
        except:
            continue
    if not candidates:
        raise RuntimeError("No ARCH models fit.")
    best = sorted(candidates, key=lambda x: x[0])[0]
    aic,name,dist,res = best
    return {"vol":res.conditional_volatility/100.0,
            "best_name":name,"best_dist":dist,"aic":aic,"res":res}

def _fallback_garch11(r, alpha=0.08, beta=0.90):
    r = r.dropna()
    if len(r) < 30:
        return {"vol": r.rolling(20).std(), "best_name":"ROLLING","best_dist":None,"aic":np.nan,"res":None}
    var0 = float(r.var())
    omega = var0*(1-alpha-beta)
    h = np.zeros(len(r))
    h[0] = var0
    for i in range(1,len(r)):
        h[i] = omega + alpha*(r.iloc[i-1]**2) + beta*h[i-1]
    vol = pd.Series(np.sqrt(h), index=r.index)
    return {"vol":vol,"best_name":"GARCH_FALLBACK","best_dist":None,"aic":np.nan,
            "res":{"alpha":alpha,"beta":beta,"omega":omega}}

def fit_best_vol_model(r):
    if ARCH_AVAILABLE:
        try:
            out = _fit_best_arch(r)
            out["engine"] = "arch"
            return out
        except Exception as e:
            print("arch failed, fallback:", e)
    out = _fallback_garch11(r)
    out["engine"] = "fallback"
    return out


# ----------------------------
# 8) REGIMES
# ----------------------------
def fit_markov_regime(r, k=3):
    rvals = (r.dropna()*100).values
    idx = r.dropna().index
    try:
        model = MarkovRegression(rvals, k_regimes=k, switching_variance=True)
        res = model.fit(disp=False)
        probs = res.smoothed_marginal_probabilities
        out = pd.DataFrame({f"regime_{i}_prob":probs[i] for i in range(k)}, index=idx)
        out["regime_current"] = out.idxmax(axis=1).str.extract("(\d+)").astype(int)
        return out
    except:
        vz = zscore(r.rolling(20).std(),60)
        rc = pd.cut(vz,[-np.inf,-0.5,0.5,np.inf],labels=[0,1,2]).astype(float)
        return pd.DataFrame({"regime_current":rc}, index=r.index)


# ----------------------------
# 9) FEATURE ENGINEERING + MACRO ENCODING
# ----------------------------
def encode_macro_value(v):
    if v is None: return 0.0
    if isinstance(v,(bool,np.bool_)): return float(int(v))
    if isinstance(v,(int,float,np.number)): return float(v)
    if isinstance(v,(list,tuple,dict,set)): return 0.0
    if isinstance(v,str):
        s=v.lower()
        mapping={
            "strong":1.0,"weak":-1.0,
            "high":1.0,"normal":0.0,"low":-1.0,
            "positive":1.0,"negative":-1.0,
            "bullish":1.0,"bearish":-1.0,"neutral":0.0
        }
        if s in mapping: return mapping[s]
        try:
            if s.endswith("%"): return float(s[:-1])/100.0
            return float(s)
        except: return 0.0
    return 0.0

def engineer_features(tkr, asset_closes, asset_highs, asset_lows, asset_volumes,
                      indicator_closes, returns, macro_dict, arch_vol, regime_df):

    price = asset_closes[tkr]
    high  = asset_highs[tkr]
    low   = asset_lows[tkr]
    volu  = asset_volumes[tkr]

    f = pd.DataFrame(index=price.index)

    # returns + momentum
    for p in [1,2,3,5,10,20,60]:
        f[f"ret_{p}d"] = safe_pct_change(price,p)
        f[f"mom_{p}d"] = price/price.shift(p)-1

    # SMAs
    for w in [5,10,20,50,100,200]:
        sma=price.rolling(w).mean()
        f[f"sma_{w}"]=sma
        f[f"px_sma_{w}"]=price/sma
        f[f"sma_{w}_slope5"]=sma.diff(5)

    # RSI
    for w in [7,14,21]:
        d = price.diff()
        gain=d.clip(lower=0).rolling(w).mean()
        loss=(-d.clip(upper=0)).rolling(w).mean()
        rs=gain/loss.replace(0,np.nan)
        f[f"rsi_{w}"]=(100-100/(1+rs)).fillna(50)

    # ATR
    tr=pd.concat([high-low,(high-price.shift(1)).abs(),(low-price.shift(1)).abs()],axis=1).max(axis=1)
    f["atr_14"]=tr.rolling(14).mean()
    f["atr_pct"]=f["atr_14"]/price

    # Bollinger
    sma20=price.rolling(20).mean()
    std20=price.rolling(20).std()
    bb_u=sma20+2*std20
    bb_l=sma20-2*std20
    f["bb_pos"]=(price-bb_l)/(bb_u-bb_l)

    # volume
    f["vol_sma20"]=volu.rolling(20).mean()
    f["vol_ratio"]=volu/f["vol_sma20"]
    f["obv"]=(np.sign(price.diff())*volu).fillna(0).cumsum()

    # volatility + regimes
    f["arch_vol"] = arch_vol.reindex(f.index)
    f = pd.concat([f, regime_df.reindex(f.index)], axis=1)

    # macro encoded numeric
    for k,v in macro_dict.items():
        f[f"macro_{k}"] = encode_macro_value(v)

    # extra indicators
    if "^VIX" in indicator_closes:
        vix=indicator_closes["^VIX"].reindex(f.index)
        f["vix"]=vix
        f["vix_chg"]=safe_pct_change(vix,1)

    if "DX-Y.NYB" in indicator_closes:
        dxy=indicator_closes["DX-Y.NYB"].reindex(f.index)
        f["dxy"]=dxy
        f["dxy_mom20"]=safe_pct_change(dxy,20)

    # oil-specific
    if tkr=="CL=F":
        if "BZ=F" in indicator_closes:
            brent=indicator_closes["BZ=F"].reindex(f.index)
            f["brent_wti_spread"]=(brent-price)/price
        if "XLE" in indicator_closes:
            xle=indicator_closes["XLE"].reindex(f.index)
            f["xle_mom20"]=safe_pct_change(xle,20)
        if "NG=F" in indicator_closes:
            ng=indicator_closes["NG=F"].reindex(f.index)
            f["ng_mom20"]=safe_pct_change(ng,20)
        f["roll_basis_60"]=price/price.rolling(60).mean()-1

    # clean
    f = f.replace([np.inf,-np.inf],np.nan)
    for c in f.columns:
        f[c] = f[c].fillna(f[c].median()) if not f[c].isna().all() else 0.0
    return f


# ----------------------------
# 10) PCA FACTORS
# ----------------------------
def make_pca_factors(ret_df, n_components=3):
    r=ret_df.dropna().apply(winsorize_series,axis=0)
    std=(r-r.mean())/r.std()
    pca=PCA(n_components=n_components,random_state=SEED)
    comps=pca.fit_transform(std.values)
    return pd.DataFrame(comps,index=std.index,columns=[f"pc{i+1}" for i in range(n_components)]),pca


# ----------------------------
# 11) ML TRAINING (LGB optional)
# ----------------------------
def time_series_train_best(X,y):
    scaler=RobustScaler()
    Xs=pd.DataFrame(scaler.fit_transform(X),index=X.index,columns=X.columns)

    candidates={
        "LR":LogisticRegression(max_iter=2000,class_weight="balanced",random_state=SEED),
        "RF":RandomForestClassifier(
            n_estimators=400,max_depth=18,min_samples_split=10,min_samples_leaf=5,
            max_features="sqrt",class_weight="balanced",n_jobs=-1,random_state=SEED),
        "GB":GradientBoostingClassifier(
            n_estimators=300,max_depth=5,learning_rate=0.04,subsample=0.8,random_state=SEED),
        "XGB":xgb.XGBClassifier(
            n_estimators=250,max_depth=6,learning_rate=0.05,
            subsample=0.8,colsample_bytree=0.8,eval_metric="logloss",random_state=SEED)
    }
    if LGB_AVAILABLE:
        candidates["LGB"]=lgb.LGBMClassifier(
            n_estimators=250,max_depth=6,learning_rate=0.05,
            subsample=0.8,colsample_bytree=0.8,random_state=SEED,verbose=-1)

    models,scores={},{}
    tscv=TimeSeriesSplit(n_splits=5)

    for name,m in candidates.items():
        fold_acc=[]; ok=True
        for tr,te in tscv.split(Xs):
            try:
                m.fit(Xs.iloc[tr],y.iloc[tr])
                pred=m.predict(Xs.iloc[te])
                fold_acc.append(accuracy_score(y.iloc[te],pred))
            except:
                ok=False; break
        if ok and fold_acc:
            models[name]=m
            scores[name]=np.mean(fold_acc)

    if not models: return None

    if len(models)>=3:
        ens=VotingClassifier([(n,models[n]) for n in models],voting="soft")
        ens.fit(Xs,y)
        models["ENS"]=ens
        scores["ENS"]=max(scores.values())+1e-6

    best=max(scores,key=scores.get)
    return {"scaler":scaler,"best_model":models[best],
            "best_name":best,"cv_score":scores[best]}


# ----------------------------
# 12) RISK METRICS
# ----------------------------
def risk_metrics(r):
    r=r.dropna()
    if len(r)<30: return {}
    mu,sig=r.mean(),r.std()
    var_95=np.quantile(r,0.05)
    cvar_95=r[r<=var_95].mean()
    sharpe=(mu/sig)*np.sqrt(252) if sig>0 else 0
    downside=r[r<0].std()
    sortino=(mu/downside)*np.sqrt(252) if downside>0 else 0
    gains=r.clip(lower=0).sum()
    losses=(-r).clip(lower=0).sum()
    omega=gains/losses if losses>0 else np.inf
    return {"mean":mu,"vol":sig*np.sqrt(252),"VaR_95":var_95,"CVaR_95":cvar_95,
            "sharpe":sharpe,"sortino":sortino,"omega":omega,
            "skew":r.skew(),"kurtosis":r.kurt()}


# ----------------------------
# 13) MONTE CARLO
# ----------------------------
def monte_carlo_forecast(px_series,vol_series,horizon_days=5,n_sims=5000,
                         jump_prob=0.02,jump_mu=-0.01,jump_sigma=0.04,df_t=5):

    px=px_series.dropna()
    if len(px)<60: return None

    r=np.log(px/px.shift(1)).dropna()
    drift=r.mean()
    vol=float(vol_series.dropna().iloc[-1])
    s0=float(px.iloc[-1])

    sims=np.zeros((n_sims,horizon_days))
    for i in range(n_sims):
        s=s0
        for t in range(horizon_days):
            shock=stats.t.rvs(df_t)*vol
            jump=np.random.normal(jump_mu,jump_sigma) if np.random.rand()<jump_prob else 0
            s=s*np.exp(drift+shock+jump)
            sims[i,t]=s
    terminal=sims[:,-1]
    return {
        "expected_return":np.mean(terminal/s0-1),
        "prob_up": float(np.mean(terminal>s0)),
        "prob_down":float(np.mean(terminal<=s0)),
        "confidence": float(max(np.mean(terminal>s0),np.mean(terminal<=s0))),
        "terminal_dist":terminal
    }


# ----------------------------
# 14) SCORECARDS + COMPOSITE
# ----------------------------
def macro_score_cards(macro,corr,current_regime_name,current_regime,oil_tkr):

    spy_f={
        "Fed policy":{
            "status":f"10Y {macro.get('yield_10y',0):.2f}%",
            "impact":"NEGATIVE" if macro.get("yield_10y",0)>4.5 else "POSITIVE",
            "reasoning":"Rates high = headwind" if macro.get("yield_10y",0)>4.5 else "Rates supportive"
        },
        "Recession risk":{
            "status":macro.get("recession_risk","Low"),
            "impact":"NEGATIVE" if macro.get("recession_risk")=="High" else "NEUTRAL",
            "reasoning":"Demand risk if recession high"
        },
        "Credit":{
            "status":"STRESS" if macro.get("credit_stress",False) else "STABLE",
            "impact":"NEGATIVE" if macro.get("credit_stress") else "POSITIVE",
            "reasoning":"Credit stress hurts risk assets"
        },
        "Liquidity":{
            "status":macro.get("liquidity_proxy","Normal"),
            "impact":"POSITIVE" if macro.get("liquidity_proxy")=="High" else "NEUTRAL",
            "reasoning":"High liquidity helps risk"
        },
        "Volatility":{
            "status":f"VIX {macro.get('vix_current',0):.1f}",
            "impact":"NEGATIVE" if macro.get("vix_current",15)>25 else "POSITIVE",
            "reasoning":"High vol reduces risk appetite"
        },
        "Regime":{
            "status":current_regime_name,
            "impact":"POSITIVE" if current_regime==0 else ("NEUTRAL" if current_regime==1 else "NEGATIVE"),
            "reasoning":"Regime sets backdrop"
        }
    }

    qqq_f={
        "Rates":{
            "status":f"10Y {macro.get('yield_10y',0):.2f}%",
            "impact":"NEGATIVE" if macro.get("yield_10y",0)>4 else "POSITIVE",
            "reasoning":"Tech very rate-sensitive"
        },
        "USD":{
            "status":macro.get("dxy_strength","Neutral"),
            "impact":"NEGATIVE" if macro.get("dxy_strength")=="Strong" else "POSITIVE",
            "reasoning":"Strong USD hurts overseas earnings"
        },
        "Regime":{
            "status":current_regime_name,
            "impact":"POSITIVE" if current_regime==0 else "NEGATIVE",
            "reasoning":"Bull regime helps tech"
        }
    }

    oil_f={
        "Demand proxy":{
            "status": f"SPY-Oil corr60 {corr.loc['SPY',oil_tkr]:.2f}" if oil_tkr in corr else "N/A",
            "impact":"NEUTRAL","reasoning":"Demand linked to growth"
        },
        "OPEC policy":{"status":"CONSTRAINED","impact":"BULLISH","reasoning":"Cuts support oil"},
        "USD strength":{
            "status":macro.get("dxy_strength","Neutral"),
            "impact":"NEGATIVE" if macro.get("dxy_strength")=="Strong" else "NEUTRAL",
            "reasoning":"Strong USD reduces affordability"
        },
        "Recession":{
            "status":macro.get("recession_risk","Low"),
            "impact":"NEGATIVE" if macro.get("recession_risk")=="High" else "NEUTRAL",
            "reasoning":"Recession reduces demand"
        }
    }

    gold_f={
        "Rates":{
            "status":f"10Y {macro.get('yield_10y',0):.2f}%",
            "impact":"NEGATIVE" if macro.get("yield_10y",0)>4 else "POSITIVE",
            "reasoning":"High real rates hurt gold"
        },
        "USD":{
            "status":macro.get("dxy_strength","Neutral"),
            "impact":"NEGATIVE" if macro.get("dxy_strength")=="Strong" else "POSITIVE",
            "reasoning":"Gold moves inverse USD"
        },
        "Safe haven":{
            "status":current_regime_name,
            "impact":"POSITIVE" if current_regime==2 else "NEUTRAL",
            "reasoning":"Risk-off regime supports gold"
        }
    }

    return spy_f,qqq_f,oil_f,gold_f

def composite_score(factors):
    return sum(
        +1 if f["impact"] in ["POSITIVE","BULLISH"] else
        -1 if f["impact"] in ["NEGATIVE","BEARISH"] else 0
        for f in factors.values()
    )


# ----------------------------
# 15) MAIN PIPELINE
# ----------------------------
def run_system():
    print("="*80)
    print("MULTI-ASSET MACRO-QUANT OIL-FIRST SYSTEM V3 (COLAB-NATIVE)")
    print("="*80)

    # ========== 1) DATA ================
    asset_data, indicator_data = collect_market_data()
    asset_closes, asset_opens, asset_highs, asset_lows, asset_volumes = extract_ohlcv(asset_data)
    indicator_closes, *_ = extract_ohlcv(indicator_data)

    all_closes = pd.concat([asset_closes, indicator_closes], axis=1).ffill(limit=5).dropna()
    returns = all_closes.pct_change().dropna()

    oil_tkr = "CL=F" if "CL=F" in asset_closes.columns else "BZ=F"
    oil_px = float(asset_closes[oil_tkr].iloc[-1])

    targets = make_targets(asset_closes)

    # ========== 2) VOL + REGIMES ============
    arch_vols, regimes = {}, {}
    for tkr in ASSETS:
        arch_vols[tkr] = fit_best_vol_model(returns[tkr])["vol"]
        regimes[tkr]    = fit_markov_regime(returns[tkr],3)

    global_regime = regimes["SPY"]
    current_regime = int(global_regime["regime_current"].dropna().iloc[-1])
    regime_names = {0:"Low Vol (Bull)",1:"Normal",2:"High Vol (Bear)"}
    current_regime_name = regime_names.get(current_regime,"Unknown")

    # ========== 3) MACRO ============
    macro = build_macro_indicators(asset_closes, indicator_closes)

    asset_ret = returns[list(ASSETS.keys())]
    pca_factors,_ = make_pca_factors(asset_ret,3)

    # ========== 4) FEATURES ===========
    features={}
    for tkr in ASSETS:
        f=engineer_features(
            tkr, asset_closes, asset_highs, asset_lows, asset_volumes,
            indicator_closes, returns, macro, arch_vols[tkr], global_regime
        )
        f=pd.concat([f, pca_factors.reindex(f.index)],axis=1)
        features[tkr]=f

    # ========== 5) ML PREDICTIONS ===========
    models,forward_preds={},{}
    for tkr in ASSETS:
        X=features[tkr]
        y=targets[tkr]["5d_binary"]
        data=pd.concat([X,y.rename("target")],axis=1).dropna(subset=["target"])
        if len(data)<300:
            print(f"[WARN] {tkr} insufficient samples.")
            continue

        Xc,yc=data.drop("target",axis=1),data["target"]
        mdl=time_series_train_best(Xc,yc)
        if mdl is None:
            print(f"[WARN] {tkr} ML failed")
            continue

        models[tkr]=mdl
        latest=Xc.iloc[-1:]
        latest_scaled=mdl["scaler"].transform(latest)
        pred_class=int(mdl["best_model"].predict(latest_scaled)[0])
        pred_prob=mdl["best_model"].predict_proba(latest_scaled)[0]
        conf=float(pred_prob.max())
        forward_preds[tkr]={
            "prediction_class":pred_class,
            "prediction_direction":"UP" if pred_class==1 else "DOWN/FLAT",
            "confidence":conf,
            "prob_up": float(pred_prob[1]),
            "prob_down":float(pred_prob[0]),
            "model_used":mdl["best_name"],
            "cv_score":mdl["cv_score"],
            "current_price":float(asset_closes[tkr].iloc[-1])
        }

    # ========== 6) MONTE CARLO ===========
    mc_forecasts={tkr: monte_carlo_forecast(asset_closes[tkr], arch_vols[tkr],5,5000)
                  for tkr in ASSETS}

    # ========== 7) RISK ===========
    risk={tkr: risk_metrics(returns[tkr]) for tkr in ASSETS}

    # ========== 8) MACRO SCORES ===========
    corr60 = asset_ret.tail(60).corr()
    spy_f,qqq_f,oil_f,gold_f = macro_score_cards(
        macro,corr60,current_regime_name,current_regime,oil_tkr
    )

    scores={
        "SPY": composite_score(spy_f),
        "QQQ": composite_score(qqq_f),
        oil_tkr: composite_score(oil_f),
        "GLD": composite_score(gold_f)
    }

    # ========== 9) COMBINED SIGNAL ===========
    combined={}
    for tkr in ASSETS:
        macro_rating = ("BULLISH" if scores.get(tkr,0)>1
                         else "BEARISH" if scores.get(tkr,0)<-1
                         else "NEUTRAL")

        ml   = forward_preds.get(tkr,{})
        mc   = mc_forecasts.get(tkr,{})
        ml_d = ml.get("prediction_direction","N/A")
        mc_d = "UP" if (mc and mc["prob_up"]>0.55) else "DOWN/FLAT"

        if macro_rating=="BULLISH" and ml_d=="UP" and mc_d=="UP" and ml.get("confidence",0)>0.65:
            combined[tkr]="üü¢ STRONG BUY"
        elif macro_rating=="BEARISH" and ml_d!="UP" and mc_d!="UP" and ml.get("confidence",0)>0.65:
            combined[tkr]="üî¥ STRONG SELL"
        elif macro_rating=="BULLISH" or ml_d=="UP":
            combined[tkr]="üü¢ MODERATE BUY"
        elif macro_rating=="BEARISH" or ml_d!="UP":
            combined[tkr]="üî¥ MODERATE SELL"
        else:
            combined[tkr]="üü° HOLD"

    # ========== 10) OUTPUT ===========
    print("\n" + "="*80)
    print("OIL-FIRST SUMMARY")
    print("="*80)
    print(f"Oil ticker: {oil_tkr}   Price: ${oil_px:.2f}")
    print(f"Regime: {current_regime_name}")
    print(f"Oil Macro Score: {scores.get(oil_tkr,0):+d}/{len(oil_f)}")
    print(f"Oil ML: {forward_preds.get(oil_tkr,{})}")
    print(f"Oil MC: {{'expected_return': {mc_forecasts.get(oil_tkr,{}).get('expected_return')}, 'prob_up': {mc_forecasts.get(oil_tkr,{}).get('prob_up')}}}")
    print(f"Oil Signal: {combined.get(oil_tkr)}")

    print("\nüõ¢Ô∏è WTI Fundamentals:")
    for k,v in oil_f.items():
        print(f"\n{k}")
        print("  Status:", v["status"])
        print("  Impact:", v["impact"])
        print("  Reason:", v["reasoning"])

    print("\n" + "="*80)
    print("ALL-ASSET SIGNALS")
    print("="*80)
    for tkr in ASSETS:
        ml=forward_preds.get(tkr,{})
        mc=mc_forecasts.get(tkr,{})
        print(f"\n{tkr} ({ASSETS[tkr]})")
        print(f"  Price: ${ml.get('current_price',np.nan):.2f}")
        print(f"  Macro Score: {scores.get(tkr,0):+d}")
        print(f"  ML Dir: {ml.get('prediction_direction','N/A')} Conf: {ml.get('confidence',0):.1%}  Model: {ml.get('model_used','N/A')}")
        if mc and mc.get("prob_up") is not None:
            print(f"  MC Prob Up: {mc['prob_up']:.1%}  ExpRet(5d): {mc['expected_return']:.2%}")
        print(f"  Combined: {combined.get(tkr)}")
        print(f"  Risk: Sharpe {risk[tkr].get('sharpe',0):.2f}, VaR95 {risk[tkr].get('VaR_95',0):.2%}")

    # ======================================================
    # ULTRA-SAFE CSV SAVER (NO pandas.to_csv USED)
    # ======================================================
    import csv

    def ultra_safe_to_csv(df, path):
        out = df.copy()
        out.index  = [str(i) for i in out.index]
        out.columns = [str(c) for c in out.columns]

        out = out.reset_index()
        out = out.astype(object).where(pd.notnull(out), "")

        header = list(out.columns)
        rows = out.values.tolist()

        with open(path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(header)
            writer.writerows(rows)

    # Save artifacts
    pred_df  = pd.DataFrame(forward_preds).T
    score_df = pd.DataFrame(scores, index=["macro_score"]).T
    risk_df  = pd.DataFrame(risk).T
    comb_df  = pd.DataFrame(combined, index=["combined_signal"]).T

    ultra_safe_to_csv(pred_df,  "forward_predictions_5d.csv")
    ultra_safe_to_csv(score_df, "macro_scores.csv")
    ultra_safe_to_csv(risk_df,  "risk_metrics.csv")
    ultra_safe_to_csv(comb_df,  "combined_signals.csv")

    print("\n‚úÖ Files saved:")
    print("  - forward_predictions_5d.csv")
    print("  - macro_scores.csv")
    print("  - risk_metrics.csv")
    print("  - combined_signals.csv")
    print("\n‚ö†Ô∏è Educational use only.")


# ---------------------------------------------------------
# RUN SYSTEM
# ---------------------------------------------------------
run_system()
